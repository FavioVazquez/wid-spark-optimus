{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RDDs and DataFrames Basics\n",
    "\n",
    "* Creating RDDs and DataFrames using SparkContext\n",
    "* Interoperability between RDDs and DataFrames\n",
    "* Multiple rows and multiple column specifications for DataFrames\n",
    "* Creating DataFrames using SQLContext\n",
    "* Selecting, editing and renaming columns in dataframes\n",
    "* Interoperability between Pandas and Spark dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import Row\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating RDDs using sc.parallelize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_data = sc.parallelize([1, \"Alice\", 50])\n",
    "simple_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_data.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_data.first() # Si fuera una lista simple_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_data.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(simple_data.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_data.take(1)[0] ## simple_data.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_data.take?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_data.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is an ERROR!\n",
    "\n",
    "* This RDD does not have \"columns\", it cannot be represented as a tabular data frame\n",
    "* DataFrames are structured datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = simple_data.toDF() # :( "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RDDs with records using sc.parallelize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = sc.parallelize([[1, \"Alice\", 50], [2, \"Bob\", 80]])\n",
    "records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is an NOT an error!\n",
    "\n",
    "* This RDD does have \"columns\", it can be represented as a tabular data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = records.toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show() # df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating dataframes using sc.parallelize() and Row() functions\n",
    "* Row functions allow specifying column names for dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(Row(id=1,name=\"Alice\",score=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prueba = sc.parallelize(Row(id=1,\n",
    "                           name=\"Alice\",\n",
    "                           score=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prueba.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sc.parallelize([Row(id=1,\n",
    "                           name=\"Alice\",\n",
    "                           score=50)])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.toDF()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working with multiple rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sc.parallelize([Row(\n",
    "                           id=1,\n",
    "                           name=\"Alice\",\n",
    "                           score=50\n",
    "                        ),\n",
    "                        Row(\n",
    "                            id=2,\n",
    "                            name=\"Bob\",\n",
    "                            score=80\n",
    "                        ),\n",
    "                        Row(\n",
    "                            id=3,\n",
    "                            name=\"Charlee\",\n",
    "                            score=75\n",
    "                        )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.toDF()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple columns with complex data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_data = sc.parallelize([Row(\n",
    "                                col_float=1.44,\n",
    "                                col_integer=10,\n",
    "                                col_string=\"John\")\n",
    "                           ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_data_df = complex_data.toDF()\n",
    "complex_data_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_data = sc.parallelize([Row(\n",
    "                                col_float=1.44, \n",
    "                                col_integer=10, \n",
    "                                col_string=\"John\", \n",
    "                                col_boolean=True, \n",
    "                                col_list=[1, 2, 3])\n",
    "                           ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_data_df = complex_data.toDF()\n",
    "complex_data_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_data = sc.parallelize([Row(\n",
    "                                col_list = [1, 2, 3], \n",
    "                                col_dict = {\"k1\": 0, \"k2\": 1, \"k3\": 2}, \n",
    "                                col_row = Row(columnA = 10, columnB = 20, columnC = 30), \n",
    "                                col_time = datetime(2014, 8, 1, 14, 1, 5)\n",
    "                            )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_data_df = complex_data.toDF()\n",
    "complex_data_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple rows with complex data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_data = sc.parallelize([Row(\n",
    "                                col_list = [1, 2, 3],\n",
    "                                col_dict = {\"k1\": 0},\n",
    "                                col_row = Row(a=10, b=20, c=30),\n",
    "                                col_time = datetime(2014, 8, 1, 14, 1, 5)\n",
    "                            ),              \n",
    "                            Row(\n",
    "                                col_list = [1, 2, 3, 4, 5], \n",
    "                                col_dict = {\"k1\": 0,\"k2\": 1 }, \n",
    "                                col_row = Row(a=40, b=50, c=60),\n",
    "                                col_time = datetime(2014, 8, 2, 14, 1, 6)\n",
    "                            ),\n",
    "                            Row(\n",
    "                                col_list = [1, 2, 3, 4, 5, 6, 7], \n",
    "                                col_dict = {\"k1\": 0, \"k2\": 1, \"k3\": 2 }, \n",
    "                                col_row = Row(a=70, b=80, c=90),\n",
    "                                col_time = datetime(2014, 8, 3, 14, 1, 7)\n",
    "                            )]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_data_df = complex_data.toDF()\n",
    "complex_data_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating DataFrames using SQLContext (SparkSession)\n",
    "\n",
    "* spark can create dataframes directly from raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.range(5)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rows specified in tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [('Alice', 50),\n",
    "        ('Bob', 80),\n",
    "        ('Charlee', 75)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.createDataFrame(data, ['Name', 'Score']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_data = [\n",
    "                 (1.0,\n",
    "                  10,\n",
    "                  \"Alice\", \n",
    "                  True, \n",
    "                  [1, 2, 3], \n",
    "                  {\"k1\": 0},\n",
    "                  Row(a=1, b=2, c=3), \n",
    "                  datetime(2014, 8, 1, 14, 1, 5)),\n",
    "\n",
    "                 (2.0,\n",
    "                  20,\n",
    "                  \"Bob\", \n",
    "                  True, \n",
    "                  [1, 2, 3, 4, 5], \n",
    "                  {\"k1\": 0,\"k2\": 1 }, \n",
    "                  Row(a=1, b=2, c=3), \n",
    "                  datetime(2014, 8, 1, 14, 1, 5)),\n",
    "\n",
    "                  (3.0,\n",
    "                   30,\n",
    "                   \"Charlee\", \n",
    "                   False, \n",
    "                   [1, 2, 3, 4, 5, 6], \n",
    "                   {\"k1\": 0, \"k2\": 1, \"k3\": 2 }, \n",
    "                   Row(a=1, b=2, c=3), \n",
    "                   datetime(2014, 8, 1, 14, 1, 5))\n",
    "                ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.createDataFrame(complex_data).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_data_df = spark.createDataFrame(complex_data, [\n",
    "        'col_integer',\n",
    "        'col_float',\n",
    "        'col_string',\n",
    "        'col_boolean',\n",
    "        'col_list',\n",
    "        'col_dictionary',\n",
    "        'col_row',\n",
    "        'col_date_time']\n",
    "    )\n",
    "complex_data_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating dataframes using SQL Context and the Row function\n",
    "* Row functions can be used without specifying column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sc.parallelize([\n",
    "    Row(1, \"Alice\", 50),\n",
    "    Row(2, \"Bob\", 80),\n",
    "    Row(3, \"Charlee\", 75)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = Row('id', 'name', 'score')  \n",
    "students = data.map(lambda r: column_names(*r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students_df = spark.createDataFrame(students)\n",
    "students_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting specific rows from dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_data_df.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_data_df.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_data_df.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting specific cells from dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_string = complex_data_df.collect()[0][2]\n",
    "cell_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_list = complex_data_df.collect()[0][4]\n",
    "cell_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_list.append(100)\n",
    "cell_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_data_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_data_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_data_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting specific columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_data_df.rdd\\\n",
    "    .map(lambda x: (x.col_string, x.col_dictionary))\\\n",
    "    .collect() # No es común ni es recomendado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_data_df.select(\n",
    "    'col_string',\n",
    "    'col_list',\n",
    "    'col_date_time'\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Editing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_data_df.rdd\\\n",
    "           .map(lambda x: (x.col_string + \" Boo\"))\\\n",
    "           .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_data_df.col_integer # complex_data_df[\"col_integer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_data_df.select(\n",
    "                   'col_integer',\n",
    "                   'col_float'\n",
    "            )\\\n",
    "           .withColumn(\n",
    "                   \"col_sum\",\n",
    "                    complex_data_df.col_integer + complex_data_df.col_float\n",
    "           )\\\n",
    "           .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_data_df.select('col_boolean')\\\n",
    "               .withColumn(\n",
    "                   \"col_opposite\",\n",
    "                   complex_data_df.col_boolean == False )\\\n",
    "               .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Editing a column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_data_df.withColumnRenamed(\"col_dictionary\",\"col_map\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_data_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_data_df.select(complex_data_df.col_string.alias(\"Name\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interoperablity between Pandas dataframe and Spark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas = complex_data_df.toPandas()\n",
    "df_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = spark.createDataFrame(df_pandas)  \n",
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark.rdd.getNumPartitions()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
