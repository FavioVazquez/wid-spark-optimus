{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download dataset\n",
    "<b>Dataset location: </b>http://files.grouplens.org/datasets/movielens/ml-latest-small.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName('Use Collaborative Filtering for movie recommendations') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "rawData = spark.read\\\n",
    "            .format('csv')\\\n",
    "            .option('header', 'true')\\\n",
    "            .load('data/movielens/ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawData.toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pick all columns except the timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "dataset = rawData.select(col('userId').cast('int'), \n",
    "                         col('movieId').cast('int'), \n",
    "                         col('rating').cast('float')\n",
    "                        )\n",
    "\n",
    "dataset.toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the distribution of rating in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.select('rating').toPandas().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into training and test data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData, testData) = dataset.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Collaborative Filtering model\n",
    "Uses the Alternating Least Squares algorithm to learn the latent factors\n",
    "* <b>maxIter: </b>The maximum number of iterations to run\n",
    "* <b>regParam: </b>Specifies the regularization parameter in ALS (defaults to 1.0)\n",
    "* <b>coldStartStrategy: </b> Strategy for handling unknown or new users/items during prediction (which was not encountered in training). Options are 'drop' and 'nan'. We will drop unknown users/items from the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "als = ALS(maxIter=5, \n",
    "          regParam=0.1, \n",
    "          userCol='userId', \n",
    "          itemCol='movieId', \n",
    "          ratingCol='rating',\n",
    "          coldStartStrategy='drop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the ALSModel using the model definition and training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = als.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the predictions for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(testData)\n",
    "predictions.toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare the distribution of values for ratings and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.select('rating', 'prediction').toPandas().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the Root Mean Square Error on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "evaluator = RegressionEvaluator(metricName='rmse', \n",
    "                                labelCol='rating',\n",
    "                                predictionCol='prediction')\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print('RMSE = ', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The ALS model can be used to get predictions for all users\n",
    "Specify the number of predictions you would like for each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userRecsAll = model.recommendForAllUsers(3)\n",
    "userRecsAll.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View the recommendations\n",
    "For each userId there is a list of tuples representing a movieId and it's rating for the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userRecsAll.toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the top user recommendations for each movie\n",
    "* The users who are most likely to like a particular movie\n",
    "* Get the top 3 users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieRecsAll = model.recommendForAllItems(3)\n",
    "movieRecsAll.toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get recommendations for a subset of users\n",
    "* Start off by creating a list of users who make up our subset\n",
    "* Convert that list to a dataframe which will be used shortly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "usersList = [148, 463, 267]\n",
    "usersDF = spark.createDataFrame(usersList, IntegerType()).toDF('userId')\n",
    "\n",
    "usersDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the recommendForUserSubset function\n",
    "This gets the recommendations for specific users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userRecs = model.recommendForUserSubset(usersDF, 5)\n",
    "userRecs.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract recommendations for specific user\n",
    "* We get a list comprising a Row object which in turn contains a list of Rows\n",
    "* To get the movie names from the movieIds so we will need to perform some transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userMoviesList = userRecs.filter(userRecs.userId == 148)\\\n",
    ".select('recommendations')\n",
    "\n",
    "userMoviesList.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract the list of recommendations\n",
    "We get the list of Rows contining the movieId and rating for the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moviesList = userMoviesList.collect()[0].recommendations\n",
    "moviesList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a DataFrame containing the movieId and rating as columns\n",
    "Use the moviesList created previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moviesDF = spark.createDataFrame(moviesList)\n",
    "moviesDF.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The movie names are stored in a csv file called movies.csv\n",
    "Load that into another dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieData = spark.read.csv('data/movielens/movies.csv',\n",
    "                              header=True,\n",
    "                              ignoreLeadingWhiteSpace= True)\n",
    "movieData.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendedMovies = movieData.join(moviesDF, on=['movieId'])\\\n",
    ".orderBy('rating', ascending=False)\\\n",
    ".select('title', 'genres', 'rating')\n",
    "\n",
    "recommendedMovies.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "def getRecommendationsForUser(userId, numRecs):\n",
    "    \n",
    "    usersDF = spark.\\\n",
    "    createDataFrame([userId], IntegerType()).\\\n",
    "    toDF('userId')\n",
    "    \n",
    "    userRecs = model.recommendForUserSubset(usersDF, numRecs)\n",
    "    \n",
    "    moviesList = userRecs.collect()[0].recommendations\n",
    "    moviesDF = spark.createDataFrame(moviesList)\n",
    "    \n",
    "    recommendedMovies = movieData.join(moviesDF, on=['movieId'])\\\n",
    "    .orderBy('rating', ascending=False)\\\n",
    "    .select('title', 'genres', 'rating')\n",
    "    \n",
    "    return recommendedMovies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendationsForUser = getRecommendationsForUser(219, 10)\n",
    "recommendationsForUser.toPandas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
